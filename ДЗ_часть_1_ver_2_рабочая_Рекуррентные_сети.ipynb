{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPgPnuGSIDTX9xeQTeP4qp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OVP2023/NN/blob/main/%D0%94%D0%97_%D1%87%D0%B0%D1%81%D1%82%D1%8C_1_ver_2_%D1%80%D0%B0%D0%B1%D0%BE%D1%87%D0%B0%D1%8F_%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "l5eqipj0-WCv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры\n",
        "ALPHABET = 'abcdefghijklmnopqrstuvwxyz '  # 26 букв + пробел\n",
        "MAX_LENGTH = 30  # Максимальная длина предложения\n",
        "VOCAB_SIZE = len(ALPHABET)\n",
        "EMBEDDING_DIM = 32\n",
        "LSTM_UNITS = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20"
      ],
      "metadata": {
        "id": "URNlWecV-WKq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словарей для преобразования символов\n",
        "char_to_idx = {char: idx for idx, char in enumerate(ALPHABET)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(ALPHABET)}"
      ],
      "metadata": {
        "id": "Y-4V3QMm-WTu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция шифрования Цезаря\n",
        "def caesar_encrypt(text, shift):\n",
        "    encrypted = []\n",
        "    for char in text.lower():\n",
        "        if char not in ALPHABET:\n",
        "            continue\n",
        "        if char == ' ':\n",
        "            encrypted.append(' ')\n",
        "        else:\n",
        "            idx = ALPHABET.index(char)\n",
        "            encrypted_char = ALPHABET[(idx + shift) % 26]\n",
        "            encrypted.append(encrypted_char)\n",
        "    return ''.join(encrypted).ljust(MAX_LENGTH, ' ')[:MAX_LENGTH]\n",
        "\n"
      ],
      "metadata": {
        "id": "QgETCwop-WZP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генератор данных\n",
        "class CaesarDataset(Dataset):\n",
        "    def __init__(self, sentences, num_samples=10000):\n",
        "        self.sentences = sentences\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        orig_text = random.choice(self.sentences).lower()[:MAX_LENGTH]\n",
        "        shift = random.randint(1, 25)\n",
        "\n",
        "        encrypted = caesar_encrypt(orig_text, shift)\n",
        "        orig_padded = orig_text.ljust(MAX_LENGTH, ' ')[:MAX_LENGTH]\n",
        "\n",
        "        # Преобразование в индексы\n",
        "        X = [char_to_idx[c] for c in encrypted]\n",
        "        y = [char_to_idx[c] for c in orig_padded]\n",
        "\n",
        "        return torch.tensor(X), torch.tensor(y)"
      ],
      "metadata": {
        "id": "HAHYVJ2P-WeW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель нейронной сети\n",
        "class DecryptModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecryptModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=EMBEDDING_DIM,\n",
        "            hidden_size=LSTM_UNITS,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.fc = nn.Linear(LSTM_UNITS, VOCAB_SIZE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output"
      ],
      "metadata": {
        "id": "E33lCNsTAsga"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для декодирования вывода модели\n",
        "def decode_output(output):\n",
        "    indices = torch.argmax(output, dim=-1).squeeze(0).cpu().numpy()\n",
        "    return ''.join(idx_to_char[idx] for idx in indices)"
      ],
      "metadata": {
        "id": "hHttyMxJAspU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Создание датасетов и загрузчиков\n",
        "sentences = [\n",
        "        \"hello world\",\n",
        "        \"neural networks\",\n",
        "        \"deep learning\",\n",
        "        \"caesar cipher\",\n",
        "        \"secret message\",\n",
        "        \"artificial intelligence\",\n",
        "        \"machine learning model\",\n",
        "        \"decode this text\",\n",
        "        \"example sentence\",\n",
        "        \"natural language processing\",\n",
        "        \"the quick brown fox jumps over the lazy dog\",\n",
        "        \"pyTorch is amazing for deep learning\",\n",
        "        \"recurrent neural networks are powerful\",\n",
        "        \"text decryption using lstm\",\n",
        "        \"caesar shift cipher decoder\",\n",
        "        'no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it',\n",
        "        'wheres mr bergstrom',\n",
        "        'i dont know although id sure like to talk to him he didnt touch my lesson plan what did he teach you',\n",
        "        'that life is worth living',\n",
        "        'the polls will be open from now until the end of recess now just in case any of you have decided to put any thought into this well have our final statements martin',\n",
        "        'i dont think theres anything left to say',\n",
        "        'bart',\n",
        "        'victory party under the slide',\n",
        "        'mr bergstrom mr bergstrom',\n",
        "        'hey hey he moved out this morning he must have a new job -- he took his copernicus costume'\n",
        "        ]\n",
        "train_dataset = CaesarDataset(sentences, num_samples=10000)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "Q_UailnaAszB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Инициализация модели\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DecryptModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Kp2KfHOLBlqx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "   total_loss = 0\n",
        "   for i, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "            # Изменяем форму для вычисления потерь\n",
        "        loss = criterion(outputs.view(-1, VOCAB_SIZE), targets.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Average Loss: {total_loss/len(train_loader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNASz_7BBl3F",
        "outputId": "ca31284a-b5ca-4e9d-fd7e-31a08935a951"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [0/157], Loss: 3.2696\n",
            "Epoch [1/20], Step [50/157], Loss: 1.9869\n",
            "Epoch [1/20], Step [100/157], Loss: 2.0454\n",
            "Epoch [1/20], Step [150/157], Loss: 1.8947\n",
            "Epoch [2/20], Step [0/157], Loss: 1.8041\n",
            "Epoch [2/20], Step [50/157], Loss: 1.7254\n",
            "Epoch [2/20], Step [100/157], Loss: 1.7252\n",
            "Epoch [2/20], Step [150/157], Loss: 1.3686\n",
            "Epoch [3/20], Step [0/157], Loss: 1.4324\n",
            "Epoch [3/20], Step [50/157], Loss: 1.2602\n",
            "Epoch [3/20], Step [100/157], Loss: 0.9668\n",
            "Epoch [3/20], Step [150/157], Loss: 0.8647\n",
            "Epoch [4/20], Step [0/157], Loss: 0.8633\n",
            "Epoch [4/20], Step [50/157], Loss: 0.7048\n",
            "Epoch [4/20], Step [100/157], Loss: 0.6481\n",
            "Epoch [4/20], Step [150/157], Loss: 0.6022\n",
            "Epoch [5/20], Step [0/157], Loss: 0.6232\n",
            "Epoch [5/20], Step [50/157], Loss: 0.5569\n",
            "Epoch [5/20], Step [100/157], Loss: 0.5383\n",
            "Epoch [5/20], Step [150/157], Loss: 0.5642\n",
            "Epoch [6/20], Step [0/157], Loss: 0.5165\n",
            "Epoch [6/20], Step [50/157], Loss: 0.5193\n",
            "Epoch [6/20], Step [100/157], Loss: 0.5356\n",
            "Epoch [6/20], Step [150/157], Loss: 0.5553\n",
            "Epoch [7/20], Step [0/157], Loss: 0.5139\n",
            "Epoch [7/20], Step [50/157], Loss: 0.5067\n",
            "Epoch [7/20], Step [100/157], Loss: 0.5488\n",
            "Epoch [7/20], Step [150/157], Loss: 0.4621\n",
            "Epoch [8/20], Step [0/157], Loss: 0.5303\n",
            "Epoch [8/20], Step [50/157], Loss: 0.4671\n",
            "Epoch [8/20], Step [100/157], Loss: 0.5231\n",
            "Epoch [8/20], Step [150/157], Loss: 0.5350\n",
            "Epoch [9/20], Step [0/157], Loss: 0.5111\n",
            "Epoch [9/20], Step [50/157], Loss: 0.4614\n",
            "Epoch [9/20], Step [100/157], Loss: 0.4627\n",
            "Epoch [9/20], Step [150/157], Loss: 0.4269\n",
            "Epoch [10/20], Step [0/157], Loss: 0.4377\n",
            "Epoch [10/20], Step [50/157], Loss: 0.4173\n",
            "Epoch [10/20], Step [100/157], Loss: 0.3919\n",
            "Epoch [10/20], Step [150/157], Loss: 0.3589\n",
            "Epoch [11/20], Step [0/157], Loss: 0.3475\n",
            "Epoch [11/20], Step [50/157], Loss: 0.3381\n",
            "Epoch [11/20], Step [100/157], Loss: 0.3062\n",
            "Epoch [11/20], Step [150/157], Loss: 0.3152\n",
            "Epoch [12/20], Step [0/157], Loss: 0.2918\n",
            "Epoch [12/20], Step [50/157], Loss: 0.2685\n",
            "Epoch [12/20], Step [100/157], Loss: 0.2642\n",
            "Epoch [12/20], Step [150/157], Loss: 0.2628\n",
            "Epoch [13/20], Step [0/157], Loss: 0.2645\n",
            "Epoch [13/20], Step [50/157], Loss: 0.2479\n",
            "Epoch [13/20], Step [100/157], Loss: 0.2419\n",
            "Epoch [13/20], Step [150/157], Loss: 0.2240\n",
            "Epoch [14/20], Step [0/157], Loss: 0.2254\n",
            "Epoch [14/20], Step [50/157], Loss: 0.2123\n",
            "Epoch [14/20], Step [100/157], Loss: 0.2165\n",
            "Epoch [14/20], Step [150/157], Loss: 0.1843\n",
            "Epoch [15/20], Step [0/157], Loss: 0.1913\n",
            "Epoch [15/20], Step [50/157], Loss: 0.1869\n",
            "Epoch [15/20], Step [100/157], Loss: 0.1812\n",
            "Epoch [15/20], Step [150/157], Loss: 0.1847\n",
            "Epoch [16/20], Step [0/157], Loss: 0.1744\n",
            "Epoch [16/20], Step [50/157], Loss: 0.1733\n",
            "Epoch [16/20], Step [100/157], Loss: 0.1767\n",
            "Epoch [16/20], Step [150/157], Loss: 0.1684\n",
            "Epoch [17/20], Step [0/157], Loss: 0.1672\n",
            "Epoch [17/20], Step [50/157], Loss: 0.1604\n",
            "Epoch [17/20], Step [100/157], Loss: 0.1623\n",
            "Epoch [17/20], Step [150/157], Loss: 0.1548\n",
            "Epoch [18/20], Step [0/157], Loss: 0.1476\n",
            "Epoch [18/20], Step [50/157], Loss: 0.1524\n",
            "Epoch [18/20], Step [100/157], Loss: 0.1474\n",
            "Epoch [18/20], Step [150/157], Loss: 0.1386\n",
            "Epoch [19/20], Step [0/157], Loss: 0.1390\n",
            "Epoch [19/20], Step [50/157], Loss: 0.1309\n",
            "Epoch [19/20], Step [100/157], Loss: 0.1361\n",
            "Epoch [19/20], Step [150/157], Loss: 0.1388\n",
            "Epoch [20/20], Step [0/157], Loss: 0.1312\n",
            "Epoch [20/20], Step [50/157], Loss: 0.1339\n",
            "Epoch [20/20], Step [100/157], Loss: 0.1329\n",
            "Epoch [20/20], Step [150/157], Loss: 0.1308\n",
            "Epoch [20/20], Average Loss: 0.1307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование модели\n",
        "test_sentences = [\n",
        "        \"hello ai\",\n",
        "        \"this is a secret message\",\n",
        "        \"neural networks can break ciphers\"\n",
        "    ]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for sentence in test_sentences:\n",
        "        shift = random.randint(1, 25)\n",
        "        encrypted = caesar_encrypt(sentence, shift)\n",
        "\n",
        "        input_seq = torch.tensor([char_to_idx[c] for c in encrypted]).unsqueeze(0).to(device)\n",
        "        output = model(input_seq)\n",
        "\n",
        "        decrypted = decode_output(output)\n",
        "\n",
        "        print(f\"\\nOriginal:  '{sentence}'\")\n",
        "        print(f\"Encrypted: '{encrypted.strip()}' (shift: {shift})\")\n",
        "        print(f\"Decrypted: '{decrypted.strip()}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv-u3qpZBmBo",
        "outputId": "ebacf9e3-69f5-4d09-bedc-3ebdea9720b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original:  'hello ai'\n",
            "Encrypted: 'olssv hp' (shift: 7)\n",
            "Decrypted: 'tello wo'\n",
            "\n",
            "Original:  'this is a secret message'\n",
            "Encrypted: 'rfgq gq y qcapcr kcqqyec' (shift: 24)\n",
            "Decrypted: 'thce le w blneee ootrrss'\n",
            "\n",
            "Original:  'neural networks can break ciphers'\n",
            "Encrypted: 'mdtqzk mdsvnqjr bzm aqdzj bhog' (shift: 25)\n",
            "Decrypted: 'teural networks are selle teee'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8Esv3HgCAR5"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}